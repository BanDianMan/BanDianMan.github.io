---
title: "ApacheKafka基础及开发"
date: 2020-05-07T09:53:22+08:00
draft: true
---

### Apache Kafka 基础及开发

#### 介绍

- Apache Kafka是一个高吞吐量的分布式发布-订阅消息系统，它被设计成可快速扩展和持久的

- Kafka经常被用来代替传统的消息代理，比如JMS和AMQP，因为它具有更高的吞吐量、可靠性和可复制性。
- Kafika是用Scala写的。

#### 特性

- 快 : 一个Kafka代理可以处理数千个客户端每秒数百兆的读写可
- 扩展 : Kafka集群可以弹性地、透明地扩展，而不需要停机。
- 经久耐用 : 消息被保存在磁盘上，并在集群内复制
- 实时 : Kafka用于构建实时数据管道和流媒体应用
- 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败） 

#### 架构

- Kafka在名为主题的类别中维护消息提要;
- 制作人将消息发布到一个Kafka主题;
- 使用者订阅主题并处理已发布消息的提要;
- Kafka集群中的服务器称为代理。

#### 使用场景

- 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。

- 消息系统：解耦和生产者和消费者、缓存消息等。

- 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。

- 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。

- 流式处理：比如spark streaming和storm

- 事件源

#### 高吞吐量和低延迟

Kafka主要通过两个关键概念来实现高吞吐量和低延迟

- 分批处理单个消息以分摊网络开销和附加/消耗块

- 使用sendfile的零拷贝l/O, (Java的NIO FileChannel transferTo方法)
  - 实现linux sendfile()系统调用，它跳过不必要的副本
  - 严重依赖于Linux PageCache
- 在一个消费者大致赶上成本估算关系的系统中，这是必要的是缓存中的数据。
  - 这使得端到端延迟非常低。

#### Kafka Roles - Broker

- 代理 : 
  - 代理是Kafka集群中的服务器;
- 每个分区都有一台服务器充当领导者，而没有一台或更多服务器作为追随者 / ISRS;
  - leader处理所有的读和写请求
  - 追随者被动地模仿领导者

- 每个服务器充当某些分区的领导者和其他分区的追随者，因此负载非常平衡。

#### Kafka Roles - Producer

- 生产者将数据发布到他们选择的主题;
  - 生产者负责选择将哪个消息分配给主题中的哪个分区;
    	- 通常通过“循环”或“语义分区”的关键
- 异步发布(不太持久)
- 所有节点都可以响应元数据请求:
  - 哪些服务器是活动的
  - .一个主题的领导者在哪里

#### Kafka Roles - Consumer

- 消费者
  - 消费者通过订阅使用消息;
  - 多个使用者可以从相同的主题中读取内容
  - 消费者被组织成消费者群体;
  - Kafka向消费者组提供消息，而不是消费者实例
    - 因此，冲销管理是在消费者群体层面
  - 消息仍然保留在Kafka上，在它们被消费后不会被删除

#### Consumer - Rebalancing

- 再平衡(由组协调器)
  - 和主题的分区被分配给组的使用者。
  - 当组中的使用者可用时，将重新分配分区,使每个消费者都能得到一定比例的份额
    - 使用者的数量不能超过分区的数量
- Messaging Models
  -  队列:消息传递给一个消费者。 
    - 所有消费者都属于同一消费群体;
  - 发布-订阅:消息发送给所有消费者。
    - 所有消费者被分配到不同的消费群体;

#### The Role of ZooKeeper

-  Kafka使用Apache ZooKeeper作为分布式服务器 
  -  它构成Kafka集群的主干，不断地监视代理/集群的健康状况 
-  Kafka的初始版本使用ZooKeeper来存储每个消费者的偏移信息;从0.10开始，Kafka有自己的内部偏移存储主题。 

#### Kafka APIs

-  [Producer API](https://kafka.apache.org/documentation.html#producerapi) 允许应用程序将记录流发布到一个或多个Kafka主题。 
-  [Consumer APL ](https://kafka.apache.org/documentation.html#consumerapi)允许应用程序订阅一个或多个主题，并处理产生给它们的记录流。 
-  [Streams API ](https://kafka.apache.org/documentation/streams)允许应用程序充当流处理器，使用一个或多个opics的输入流，并将输出流生成一个或多个输出主题，从而有效地将输入流转换为输出流。 
- [Connector APl](https://kafka.apache.org/documentation.html#connect) 允许构建和运行将Kafka opics连接到现有应用程序或数据系统的reu sable生产者或消费者 
  -  到关系数据库的连接器可能捕获对表的每个更改。 

####  消息顺序 

- 仅在一个主题的分区内保证排序
- 确保一个主题的全局排序:
  - 如果所有消息必须在一个主题内排序，那么使用一个分区
  - 如果消息可以按照某些属性排序
    - 按键对分区中的消息分组(根据生成器中的属性定义)
    - 在一个使用者组中为每个分区配置一个使用者实例
- 注意
  - 一个分区内的数据将按照写入的顺序存储，因此从一个分区读取的数据将按照该分区的顺序读取。

#### 消息复制

- 持久性可以使用“生产者配置请求”配置
  - 0 -  生产者从不等待ack 
  - 1 -  在leader副本收到数据后，生产者得到一个ack 
  - -1 / all -在所有ISRs(同步复制)接收到数据后，生产者得到一个ack

-  还可以配置最小可用ISR，以便在没有足够的副本可用来复制数据时返回错误 

#### 数据丢失

- Kafka Producer API

  - 消息成批地在缓冲区中累积
  - 消息按分区批量处理，在批处理级别重试
  - 重试后丢弃的过期批

- Data Loss at Producer

  - 在终止时未能关闭/刷新生成器
  - 当acks =0或重试耗尽时，由于通信或其他错误而丢弃的批

- 数据生成的速度比交付的速度快，导致buffer详尽异常

  
