<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>我的个人空间</title>
    <link>https://BanDianMan.github.io/</link>
    <description>Recent content on 我的个人空间</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 May 2020 09:34:52 +0800</lastBuildDate>
    
	<atom:link href="https://BanDianMan.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Hive笔记(一)</title>
      <link>https://BanDianMan.github.io/post/hive%E7%AC%94%E8%AE%B0%E4%B8%80/</link>
      <pubDate>Thu, 07 May 2020 09:34:52 +0800</pubDate>
      
      <guid>https://BanDianMan.github.io/post/hive%E7%AC%94%E8%AE%B0%E4%B8%80/</guid>
      <description>Hive概述 什么是Hive ?  Hives是基于Hadoop构建的一个数据仓库工具 可以将结构化的数据映射为一张数据库表 提供HQL(HiveSQL)查询功能 由Facebook实现并开源 底层数据存储在HDFS上 Hive的本质是将SQL语句转换为MapReduce任务运行 使不熟悉MapReduce的用户很方便的利用HQL处理和计算HDFS上的结构化数据,适用于离线的批量数据计算   Hive 依赖于HDFS存储数据,Hive将HQL转换成MapReduce执行,所以说Hive是基于Hadoop的一个数据仓库工具,实质就是一款基于HDFS的MapReduce的计算框架,对存储在HDFS中的数据进行分析和管理  为什么使用Hive ?  友好的接口 : 操作接口采用类似SQL的语法,提供快速开发的能力 低学习成本 : 避免了写MapReduce,减少开发人员的学习成本 好的扩展性 : 可自由的扩展集群规模而无需重启服务,支持用户自定义函数  Hive的特点 优点 :  可扩展性 简化MR开发 自定义函数,格式 庞大活跃的社区  缺点 :  不支持记录级别的增删改查操作 查询延时严重 不支持事物  Hive与RDBMS 的对比 数据表(Tables)  分为内部表和外部表 内部表(管理表)  HDFS中为所属数据库目录下的子文件夹 数据完全由Hive管理,删除表(元数据) 会删除数据   外部表 (External Tables)  数据保存在指定位置的HDFS路径中 Hive不完全管理数据,删除表(元数据)不会删除数据    内部表和外部表的区别  删除内部表，删除表元数据和数据 删除外部表，删除元数据，不删除数据  内部表和外部表的使用选择 如果数据的所有处理都在 Hive 中进行，那么倾向于 选择内部表，但是如果 Hive 和其他工具要针对相同的数据集进行处理，外部表更合适。</description>
    </item>
    
    <item>
      <title>深度学习之图像处理与分析</title>
      <link>https://BanDianMan.github.io/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B8%8E%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 07 May 2020 09:09:34 +0800</pubDate>
      
      <guid>https://BanDianMan.github.io/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B8%8E%E5%88%86%E6%9E%90/</guid>
      <description>深度学习之图像处理与分析  目录  人工智能和深度学习概论 图像基础 深度学习基础 深度学习的基本数学 理解的人工神经网络  人工智能和深度学习概论 中国的AI  2017年7月，国务院发布白皮书，使中国到2030年成为全球AI领导者，行业价值1500亿美元 到2030年投资70亿美元，其中包括在北京的一个研究园的20亿美元 全球AI资金占主导地位48％，而美国在2017年为38％ 中国的AI公司总数为23％，而美国2017年为42％  AI与ML与DL  Artificial intelligence(人工智能)  使人类通常执行的智力任务自动化的努力   Machine Learning(机器学习)  使系统无需进行显式编程即可自动从数据进行改进   Deep Learning(深度学习)  机器学习的特定子领域 侧重于学习越来越有意义的表示形式的连续层    人工神经网络  最初于1950年代进行调查，始于1980年代 不是真正的大脑模型 受到神经生物学研究的宽松启发  深度学习的深度如何？  深度学习是人工神经网络的重塑，具有两层以上 “深入”并不是指通过这种方法获得的更深刻的理解 它代表连续表示层的想法  深度学习框架 我们的深度学习技术堆栈 GPU和CUDA  GPU(Graphics Processing Unit):  数百个更简单的内核 数千个并发的硬件线程 最大化浮点吞吐量   CUDA(Compute Unified Device Architecture)  并行编程模型，可通过利用GPU显着提高计算性能   cuDNN（CUDA深度神经网络库）  GPU加速的神经网络原语库 它为以下方面提供了高度优化的实现：卷积，池化，规范化和激活层    设置深度学习环境  安装Anaconda3-5.</description>
    </item>
    
    <item>
      <title>基于SparkStreaming的流数据处理和分析</title>
      <link>https://BanDianMan.github.io/post/%E5%9F%BA%E4%BA%8Esparkstreaming%E7%9A%84%E6%B5%81%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E5%88%86%E6%9E%90/</link>
      <pubDate>Wed, 06 May 2020 20:11:44 +0800</pubDate>
      
      <guid>https://BanDianMan.github.io/post/%E5%9F%BA%E4%BA%8Esparkstreaming%E7%9A%84%E6%B5%81%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E5%88%86%E6%9E%90/</guid>
      <description>基于Spark Streaming的流数据处理和分析 一 Spark Streaming 1 Spark Streaming概述 1.1 实时数据处理的动机  以前所未有的速度创造数据  来自移动，网络，社交，物联网的指数数据增长&amp;hellip; 联网设备：2012年为9B，到2020年将达到50B 到2020年，超过1万亿个传感器   我们如何实时利用数据的价值？  价值会迅速下降→立即获取价值 从被动分析到直接运营 解锁新的竞争优势 需要全新的方法    1.2 跨行业的用例 1.3 什么是Spark Streaming？ Apache Spark核心API的扩展，用于流处理。该框架提供具有良好的容错能力、可扩展性、高通量、低延迟的优点
1.4 流引擎对比 1.5 流处理架构 1.6 微批量架构  传入数据作为离散流（DStream） 流被细分为微批。从Spark 2.3.1起延迟可达到1毫秒（在此之前大约100毫秒） 每个微批处理都是一个RDD –可以在批处理和流之间共享代码  2 Spark Streaming 操作 2.1 Streaming Context Streaming Context消费Spark中的数据流，数据流输入后， Streaming Context会将数据流分成批数据
 一个JVM中只能激活一个StreamingContext StreamingContext在停止后无法重新启动，但可以重新创建  2.2 DStream Discretized Stream（离散流）或DStream是Spark Streaming提供的基本抽象
2.2.1 Input DStreams 和 Receivers Streaming Context只能在Driver端，Receiver可以在Executor端</description>
    </item>
    
    <item>
      <title>ApacheNiFi介绍</title>
      <link>https://BanDianMan.github.io/post/apachenifi%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Wed, 06 May 2020 15:23:58 +0800</pubDate>
      
      <guid>https://BanDianMan.github.io/post/apachenifi%E4%BB%8B%E7%BB%8D/</guid>
      <description>Apache NiFi基础及架构  Apache NiFi介绍  Apache NiFi是一个易于使用，功能强大且可靠的系统，可通过编排和执行数据流来处理和分发数据  Apache NiFiis使系统之间的数据流自动化 基于Web的用户界面 高度可配置  容忍损失与保证交付 低延迟与高吞吐量   资料来源  从头到尾跟踪数据流   专为扩展而设计  构建定制处理器   安全  SSL，SSH，HTTPS，加密内容等      NiFi子项目-MiNiFi  MiNiFi是一种补充性的数据收集方法，是对NiFiin数据流管理的核心原则的补充，侧重于在创建源时收集数据  NiFilives位于数据中心中-为它提供企业服务器或它们的集群 MiNiFiLive距离数据出生地很近，并且是该设备或系统上的访客    NiFi功能  保证交付 数据缓冲 优先排队 流特定的QoS  延迟与吞吐量 损耗容限   资料来源 支持推拉模型 视觉命令与控制 流模板 可插拔/多角色安全 专为扩展而设计  丰富的内置处理器 广泛的支持和3rdcustom处理器   聚类  核心概念  FlowFile – 表示在系统中移动的每个对象 Proessor(处理器) – 执行实际工作，例如系统之间的数据路由，转换或中介  处理器可以访问给定FlowFile及其内容流的属性 处理器在给定单元中进行提交或回滚工作   Connection(连接) – 通过充当队列来提供处理器之间的实际链接 Flow Controller(流控制器)–充当代理，促进按计划在处理器之间交换FlowFiles Process Group(流程组) – 是一组特定的流程及其联系  允许创建可重复使用的组件    Apache NiFi架构 Apache NiFi集群  零主集群 每个节点对数据执行相同的任务，但对不同的数据集执行相同的任务 管理员选择了一个集群协调员，负责协调集群中各节点之间的连接性。  NiFi Site-to-Site  两个NiFi instances之间的直接通信 推到接收器上的输入端口，或从信源上的输出端口拉 处理负载平衡和可靠的交付 使用证书的安全连接（可选）  Site-to-Site Push  源将远程进程组连接到目标上的输入端口 Site-to-Site 负责群集中各个节点之间的负载平衡  Site-to-Site Pull  目标将远程进程组连接到源上的输出端口 如果源是集群，则每个节点将从群集中的每个节点中提取  Site-to-Site Client  任何要推动或退出NiFi的客户  Flow File  FlowFile表示在系统中移动的每个对象  Header: key/value 对属性 Content: 零个或多个字节    FlowFileProcessor  处理器实际执行工作:  操作FlowFilecontent  数据路由，数据转换等   提交或回滚工作 使用/添加/更新属性    Connection  连接提供了处理器之间的实际联系  这些充当队列，并允许各种进程以不同的速率进行交互 可以动态地对这些队列进行优先级排序，并可以在负载上设置上限，从而实现Back Pressure  Back Pressure是指在不再计划运行作为连接源的组件之前，应允许队列中存在多少数据 NiFi提供了两个Back Pressure配置元素  FolwFiles数 数据大小        Flow Controller  NiFi dataflow调度程序和执行引擎:  维护有关进程如何连接和管理所有进程使用的线程及其分配的知识 充当代理，促进处理器之间的FlowFile交换    Process Group  流程组是一组特定的流程及其连接  通过输入端口接收数据，并通过输出端口发送数据 流程组允许仅通过组合其他组件来创建全新的组件  输入口 输出口      Processors(处理器)  数据提取处理器  ListSFTP, FetchSFTP, ListFiles, FetchFiles, GetFile, ListHDFS, FetchHDFS, &amp;hellip; etc   路由和中介处理器  路由和中介处理器   数据库访问处理器  ExecuteSQL，PutSQL，ListDatabaseTables等   属性提取处理器  UpdateAttribute，EvaluateJSONPath，ExtractText等   系统交互处理器  ExecuteScript，ExecuteProcess，ExecuteStreamCommand等   数据转换处理器  ReplaceText，SplitText，MergeContent，&amp;hellip;   发送数据处理器  PutSFTP, PutFile, PutHDFS, PublishKafka, ConsumeKafka, &amp;hellip;    处理器关系  流文件通过使用处理器之间的关系进行验证的连接从一个处理器移动到另一个处理器  每当建立连接时，开发人员都会在这些处理器之间选择一个或多个关系 SUCCESS  流文件成功完成流程后移至下一个流程   FAILURE  流文件在失败的流程后移至下一个流程      DEMO &amp;hellip;</description>
    </item>
    
  </channel>
</rss>